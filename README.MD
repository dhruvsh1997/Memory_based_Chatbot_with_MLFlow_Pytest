# ğŸ¤– MLFlow_Pytest_Chatbot

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-2.3.0-green.svg)](https://flask.palletsprojects.com/)
[![MLflow](https://img.shields.io/badge/MLflow-Tracking-orange.svg)](https://mlflow.org/)
[![Pytest](https://img.shields.io/badge/Pytest-Testing-red.svg)](https://pytest.org/)
[![Groq](https://img.shields.io/badge/Groq-LLaMA_3.3_70B-purple.svg)](https://groq.com/)

A production-ready chatbot application that combines **Flask web framework**, **Groq's LLaMA 3.3 70B model**, **MLflow experiment tracking**, and **Pytest testing** to deliver a robust, monitored, and tested conversational AI experience.

## ğŸŒŸ Key Features

- **ğŸ§  AI-Powered Conversations**: Leverages Groq's LLaMA 3.3 70B Versatile model for intelligent responses
- **ğŸ“Š MLflow Experiment Tracking**: Comprehensive logging of chat sessions, metrics, and artifacts
- **ğŸ§ª Pytest Testing Framework**: Automated testing to ensure reliability and functionality
- **ğŸ’¾ Persistent Chat History**: CSV-based storage for conversation logging
- **ğŸ³ Docker Support**: Containerized deployment with Docker and docker-compose
- **ğŸ¨ Modern UI**: Clean, responsive chat interface

---

## ğŸ—ï¸ Project Architecture

```
MLFlow_Pytest_Chatbot/
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html          # Chat interface UI
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ test_app.py            # Pytest test suite
â”œâ”€â”€ Dockerfile             # Docker configuration
â””â”€â”€ docker-compose.yml     # Multi-container setup
```

---

## ğŸ“ˆ MLflow Integration Deep Dive

### Why MLflow?

MLflow transforms this chatbot from a simple application into a **production-grade ML system** with comprehensive experiment tracking, making it ideal for:

- **Performance Monitoring**: Track response times and token usage
- **Conversation Analytics**: Analyze chat patterns and model performance
- **Reproducibility**: Maintain detailed logs of all interactions
- **Model Comparison**: Compare different prompts or model configurations

### MLflow Components in Action

#### ğŸ¯ **Experiment Organization**
```python
mlflow.set_experiment("Groq_Chatbot_Experiments")
```
- Creates a dedicated experiment space for all chatbot runs
- Organizes multiple chat sessions under a single experiment umbrella

#### ğŸ“Š **Comprehensive Metrics Tracking**
Every chat interaction logs:

| Metric | Description | Purpose |
|--------|-------------|---------|
| `response_time` | Time taken to generate response | Performance monitoring |
| `input_tokens` | Tokens in user question | Cost analysis |
| `output_tokens` | Tokens in AI response | Response complexity tracking |
| `total_tokens` | Combined token usage | Total resource consumption |

#### ğŸ”§ **Parameter Logging**
```python
mlflow.log_param("question", user_msg)
mlflow.log_param("answer", answer)
mlflow.log_param("model", "llama-3.3-70b-versatile")
```
- Captures the context of each conversation
- Enables search and filtering of specific interactions

#### ğŸ“ **Artifact Management**
MLflow automatically saves four types of artifacts for each chat session:

1. **ğŸ“‹ Current Q&A Pair** (`current_qa/`)
   ```json
   {
     "timestamp": "2025-09-02 14:30:15",
     "question": "What is machine learning?",
     "answer": "Machine learning is...",
     "response_time": 1.23,
     "input_tokens": 15,
     "output_tokens": 150,
     "total_tokens": 165
   }
   ```

2. **ğŸ” Credentials Info** (`credentials/`)
   ```json
   {
     "api_key": "gsk_abcd...",
     "model": "llama-3.3-70b-versatile"
   }
   ```

3. **ğŸ“œ Complete Chat History** (`chat_history/`)
   - Full CSV export of all conversations
   - Enables historical analysis and reporting

4. **ğŸ¤– Model Information** (`model_info/`)
   ```json
   {
     "model_name": "llama-3.3-70b-versatile",
     "provider": "Groq",
     "api_endpoint": "https://api.groq.com"
   }
   ```

### MLflow Dashboard Benefits

Access the MLflow UI at `http://localhost:5002` to:

- **ğŸ“ˆ Visualize Performance Trends**: Response time distribution, token usage patterns
- **ğŸ” Search Conversations**: Find specific questions or topics
- **ğŸ“Š Generate Reports**: Export data for business intelligence
- **ğŸ”„ Compare Sessions**: Analyze different conversation patterns

---

## ğŸ§ª Pytest Testing Strategy

### Testing Philosophy

The Pytest integration ensures **reliability** and **quality assurance** by validating that the chatbot can:
- âœ… Handle user inputs correctly
- âœ… Generate meaningful responses
- âœ… Maintain API connectivity
- âœ… Return proper response formats

### Test Structure

#### **Fixture Setup**
```python
@pytest.fixture
def client():
    app = create_app()
    app.config['TESTING'] = True
    with app.test_client() as c:
        yield c
```
- Creates an isolated testing environment
- Ensures tests don't interfere with production data

#### **Core Functionality Test**
```python
def test_chat_with_message(client):
    resp = client.post('/chat', json={"message": "Hello, how are you?"})
    assert resp.status_code == 200
    data = resp.get_json()
    assert "response" in data
    assert isinstance(data["response"], str)
    assert len(data["response"]) > 0
```

**What this test validates:**
- ğŸŒ **HTTP Endpoint Functionality**: POST request handling
- ğŸ“¡ **API Integration**: Groq API connectivity
- ğŸ“ **Response Format**: JSON structure validation
- ğŸ’¬ **Content Quality**: Non-empty response generation

### Testing Benefits

| Benefit | Description |
|---------|-------------|
| **ğŸ›¡ï¸ Quality Assurance** | Catches integration issues before deployment |
| **ğŸ”„ Continuous Integration** | Automated testing in CI/CD pipelines |
| **ğŸ“Š Reliability Metrics** | Quantifiable success rates |
| **ğŸ› Bug Prevention** | Early detection of API or code issues |

---

## âš™ï¸ Installation & Setup

### Prerequisites
- Python 3.8+
- Docker & Docker Compose (optional)
- Groq API Key

### Method 1: Local Development

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd MLFlow_Pytest_Chatbot
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure environment**
   ```bash
   # Create .env file
   echo "GROQ_API_KEY=your_groq_api_key_here" > .env
   echo "MLFLOW_TRACKING_URI=./mlruns" >> .env
   echo "SECRET_KEY=your_secret_key_here" >> .env
   ```

4. **Run the application**
   ```bash
   python app.py
   ```

### Method 2: Docker Deployment

```bash
# Build and run with docker-compose
docker-compose up --build
```

**Service Endpoints:**
- ğŸŒ **Chatbot Application**: `http://localhost:5000`
- ğŸ“Š **MLflow Dashboard**: `http://localhost:5002`

---

## ğŸ§ª Running Tests

### Execute Test Suite
```bash
# Run all tests
pytest test_app.py -v

# Run with coverage
pytest test_app.py --cov=app

# Run specific test
pytest test_app.py::test_chat_with_message -v
```

### Expected Test Output
```
======================== test session starts ========================
collected 1 item

test_app.py::test_chat_with_message PASSED             [100%]

======================== 1 passed in 2.34s ========================
```

---

## ğŸ“Š MLflow Experiment Tracking

### Starting MLflow UI
```bash
# Local MLflow server
mlflow ui --backend-store-uri ./mlruns --port 5002

# Or access via Docker
docker-compose up mlflow
```

### Key MLflow Features

#### **ğŸ›ï¸ Experiment Dashboard**
- View all chat sessions in chronological order
- Filter by parameters (questions, model, timestamps)
- Compare performance metrics across sessions

#### **ğŸ“ˆ Metrics Visualization**
- Response time trends
- Token usage analytics
- Performance distribution charts

#### **ğŸ—‚ï¸ Artifact Management**
- Download conversation logs
- Access detailed session information
- Export data for external analysis

#### **ğŸ” Search & Filter**
- Find specific conversations by keywords
- Filter by date ranges or performance metrics
- Export filtered datasets

---

## ğŸ¯ Architecture Benefits

### MLflow + Pytest Synergy

| Component | Purpose | Benefit |
|-----------|---------|---------|
| **MLflow** | Production monitoring | ğŸ“Š Data-driven insights into chatbot performance |
| **Pytest** | Quality assurance | ğŸ›¡ï¸ Confidence in deployment reliability |
| **Combined** | DevOps excellence | ğŸš€ Production-ready ML application |

### Production Readiness Features

- **ğŸ”„ Error Handling**: Graceful degradation when MLflow or API fails
- **ğŸ“± Responsive Design**: Mobile-friendly chat interface
- **âš¡ Performance Tracking**: Real-time metrics collection
- **ğŸ”’ Security**: API key masking in logs
- **ğŸ“ˆ Scalability**: Docker-based deployment ready for cloud

---

## ğŸ¨ User Interface

The chatbot features a modern, intuitive interface with:

- **ğŸ’™ Clean Design**: Professional blue theme with smooth animations
- **ğŸ’¬ Message Bubbles**: Distinct styling for user and bot messages
- **â³ Loading Animation**: Engaging dot animation during response generation
- **ğŸ“± Responsive Layout**: Works seamlessly across devices
- **âŒ¨ï¸ Keyboard Support**: Send messages with Enter key

---

## ğŸ“ Data Storage

### Chat History Management
- **Format**: CSV files for easy analysis
- **Structure**: Timestamp, question, answer, performance metrics
- **Persistence**: Automatic saving after each interaction
- **Integration**: Seamless MLflow artifact logging

### MLflow Experiment Data
- **Local Storage**: `./mlruns` directory
- **Organization**: Experiments â†’ Runs â†’ Artifacts
- **Backup**: Easy to backup and migrate
- **Sharing**: Export capabilities for team collaboration

---

## ğŸ”§ Configuration Options

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `GROQ_API_KEY` | Groq API authentication key | Required |
| `MLFLOW_TRACKING_URI` | MLflow storage location | `./mlruns` |
| `SECRET_KEY` | Flask session security key | `secret_key` |

### Customization Points

- **ğŸ¨ UI Styling**: Modify CSS in `templates/index.html`
- **ğŸ¤– System Prompt**: Adjust chatbot personality in `GroqChatbot.__init__()`
- **ğŸ“Š Metrics**: Add custom metrics in the MLflow logging section
- **ğŸ§ª Tests**: Extend test coverage in `test_app.py`

---

## ğŸš€ Deployment

### Local Development
```bash
python app.py
# Access: http://localhost:5000
```

### Docker Production
```bash
docker-compose up -d
# Chatbot: http://localhost:5000
# MLflow: http://localhost:5002
```

### Cloud Deployment
- Compatible with AWS, GCP, Azure
- Requires external MLflow tracking server for production
- Environment variable configuration for cloud APIs

---

## ğŸ” Monitoring & Analytics

### Real-time Monitoring
- **Response Time Tracking**: Identify performance bottlenecks
- **Token Usage Analysis**: Cost optimization insights
- **Error Rate Monitoring**: System health indicators
- **User Interaction Patterns**: Usage analytics

### Business Intelligence
- **ğŸ“ˆ Usage Trends**: Daily/weekly conversation volumes
- **ğŸ¯ Popular Topics**: Most frequently asked questions
- **âš¡ Performance Metrics**: Average response times and token efficiency
- **ğŸ“Š Export Capabilities**: Data export for external BI tools

---

## ğŸ¤ Contributing

### Development Workflow
1. **ğŸ”§ Setup**: Install dependencies and configure environment
2. **ğŸ§ª Test**: Run pytest suite before making changes
3. **ğŸ“Š Monitor**: Check MLflow for performance impacts
4. **ğŸ”„ Iterate**: Use tracking data to guide improvements

### Adding New Features
- Extend pytest coverage for new functionality
- Add relevant MLflow metrics for monitoring
- Update documentation and examples

---

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

---

## ğŸ‰ Conclusion

This chatbot project demonstrates **modern ML engineering practices** by combining:

- **ğŸ¤– Advanced AI**: State-of-the-art language model integration
- **ğŸ“Š Experiment Tracking**: Production-grade monitoring with MLflow
- **ğŸ§ª Quality Assurance**: Automated testing with Pytest
- **ğŸ³ DevOps**: Containerized deployment ready for any environment

The integration of MLflow and Pytest transforms a simple chatbot into a **professional-grade ML application** suitable for production deployment, continuous monitoring, and iterative improvement.

---
MLFLOW UI Port Switch Code : mlflow ui --port 5002

*Built with â¤ï¸ using Flask, MLflow, Pytest, and Groq LLaMA 3.3 70B*

